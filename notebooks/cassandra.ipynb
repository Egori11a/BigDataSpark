{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e998df01-cf82-4cce-b9e2-9626c2491bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL driver visible to JVM: True\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "jar_path = \"/opt/shared-jars/postgresql-42.7.5.jar\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Integration\") \\\n",
    "    .config(\"spark.jars\", jar_path) \\\n",
    "    .config(\"spark.driver.extraClassPath\", jar_path) \\\n",
    "    .config(\"spark.executor.extraClassPath\", jar_path) \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"cassandra\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Повторная проверка\n",
    "print(\"PostgreSQL driver visible to JVM:\",\n",
    "      spark._jvm.Thread.currentThread().getContextClassLoader().getResources(\"org/postgresql/Driver.class\").hasMoreElements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa40e37-6e05-488e-a3a4-a7bdc7983328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, avg, desc, coalesce, to_date, lit\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# === Инициализация SparkSession ===\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Full Integration: PostgreSQL + Cassandra\") \\\n",
    "    .config(\"spark.jars\", \"/opt/shared-jars/postgresql-42.7.5.jar,/opt/shared-jars/spark-cassandra-connector-assembly_2.12-3.2.0.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/shared-jars/postgresql-42.7.5.jar:/opt/shared-jars/spark-cassandra-connector-assembly_2.12-3.2.0.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/opt/shared-jars/postgresql-42.7.5.jar:/opt/shared-jars/spark-cassandra-connector-assembly_2.12-3.2.0.jar\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"cassandra\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# === Параметры подключения к PostgreSQL ===\n",
    "url = \"jdbc:postgresql://host.docker.internal:65432/mydatabase\"\n",
    "properties = {\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mysecretpassword\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# === Загрузка и объединение CSV-файлов ===\n",
    "csv_files = [(i, f\"/home/jovyan/work/data/MOCK_DATA_{i}.csv\") for i in range(1, 11)]\n",
    "\n",
    "def load_file_with_offset(file_num, file_path):\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"multiLine\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\") \\\n",
    "        .csv(file_path)\n",
    "\n",
    "    offset = 1000 * (file_num - 1)\n",
    "\n",
    "    df = df.withColumn(\"id\", (col(\"id\") + offset).cast(\"integer\")) \\\n",
    "        .withColumn(\"customer_age\", col(\"customer_age\").cast(\"integer\")) \\\n",
    "        .withColumn(\"product_quantity\", col(\"product_quantity\").cast(\"integer\")) \\\n",
    "        .withColumn(\"sale_customer_id\", col(\"sale_customer_id\").cast(\"integer\")) \\\n",
    "        .withColumn(\"sale_seller_id\", col(\"sale_seller_id\").cast(\"integer\")) \\\n",
    "        .withColumn(\"sale_product_id\", col(\"sale_product_id\").cast(\"integer\")) \\\n",
    "        .withColumn(\"sale_quantity\", col(\"sale_quantity\").cast(\"integer\")) \\\n",
    "        .withColumn(\"product_reviews\", col(\"product_reviews\").cast(\"integer\")) \\\n",
    "        .withColumn(\"product_price\", col(\"product_price\").cast(\"decimal(10,2)\")) \\\n",
    "        .withColumn(\"product_weight\", col(\"product_weight\").cast(\"decimal(10,2)\")) \\\n",
    "        .withColumn(\"product_rating\", col(\"product_rating\").cast(\"decimal(3,1)\")) \\\n",
    "        .withColumn(\"sale_total_price\", col(\"sale_total_price\").cast(\"decimal(10,2)\")) \\\n",
    "        .withColumn(\"sale_date\", coalesce(to_date(col(\"sale_date\"), \"M/d/yyyy\"), to_date(col(\"sale_date\"), \"MM/dd/yyyy\"))) \\\n",
    "        .withColumn(\"product_release_date\", coalesce(to_date(col(\"product_release_date\"), \"M/d/yyyy\"), to_date(col(\"product_release_date\"), \"MM/dd/yyyy\"))) \\\n",
    "        .withColumn(\"product_expiry_date\", coalesce(to_date(col(\"product_expiry_date\"), \"M/d/yyyy\"), to_date(col(\"product_expiry_date\"), \"MM/dd/yyyy\")))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef3774-a8bf-427a-943e-e41b8803a10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальный ID: 1\n",
      "Максимальный ID: 10000\n",
      "Общее количество записей: 10000\n"
     ]
    }
   ],
   "source": [
    "# Загружаем и объединяем все файлы с переиндексацией\n",
    "df_final = None\n",
    "for file_num, file_path in csv_files:\n",
    "    df = load_file_with_offset(file_num, file_path)\n",
    "    if df_final is None:\n",
    "        df_final = df\n",
    "    else:\n",
    "        df_final = df_final.union(df)\n",
    "\n",
    "# Проверяем диапазоны ID\n",
    "print(\"Минимальный ID:\", df_final.agg({\"id\": \"min\"}).collect()[0][0])\n",
    "print(\"Максимальный ID:\", df_final.agg({\"id\": \"max\"}).collect()[0][0])\n",
    "print(\"Общее количество записей:\", df_final.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca24c64-6a97-496d-a83d-3ec5b9032c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = df.select(\"sale_customer_id\", \"customer_first_name\", \"customer_last_name\", \n",
    "                         \"customer_age\", \"customer_email\", \"customer_country\", \n",
    "                         \"customer_postal_code\", \"customer_pet_type\", \n",
    "                         \"customer_pet_name\", \"customer_pet_breed\").distinct()\n",
    "\n",
    "sellers_df = df.select(\"sale_seller_id\", \"seller_first_name\", \"seller_last_name\", \n",
    "                       \"seller_email\", \"seller_country\", \"seller_postal_code\").distinct()\n",
    "\n",
    "products_df = df.select(\"sale_product_id\", \"product_name\", \"product_category\", \n",
    "                        \"product_price\", \"product_quantity\", \"product_weight\", \n",
    "                        \"product_color\", \"product_size\", \"product_brand\", \n",
    "                        \"product_material\", \"product_description\", \n",
    "                        \"product_rating\", \"product_reviews\", \n",
    "                        \"product_release_date\", \"product_expiry_date\").distinct()\n",
    "\n",
    "stores_df = df.select(\"store_name\", \"store_location\", \"store_city\", \"store_state\", \n",
    "                      \"store_country\", \"store_phone\", \"store_email\").distinct()\n",
    "\n",
    "suppliers_df = df.select(\"supplier_name\", \"supplier_contact\", \"supplier_email\", \n",
    "                         \"supplier_phone\", \"supplier_address\", \"supplier_city\", \n",
    "                         \"supplier_country\").distinct()\n",
    "\n",
    "sales_df = df.select(\"id\", \"sale_customer_id\", \"sale_seller_id\", \"sale_product_id\", \n",
    "                     \"sale_quantity\", \"sale_total_price\", \"sale_date\", \"store_name\").distinct()\n",
    "\n",
    "customers_df.write.jdbc(url=url, table=\"customers\", mode=\"overwrite\", properties=properties)\n",
    "sellers_df.write.jdbc(url=url, table=\"sellers\", mode=\"overwrite\", properties=properties)\n",
    "products_df.write.jdbc(url=url, table=\"products\", mode=\"overwrite\", properties=properties)\n",
    "stores_df.write.jdbc(url=url, table=\"stores\", mode=\"overwrite\", properties=properties)\n",
    "suppliers_df.write.jdbc(url=url, table=\"suppliers\", mode=\"overwrite\", properties=properties)\n",
    "sales_df.write.jdbc(url=url, table=\"sales\", mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bbd5c-0616-4ef6-9ce8-52912f0190c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jvm.Thread.currentThread().getContextClassLoader().getResources(\"org/apache/spark/sql/cassandra/DefaultSource.class\").hasMoreElements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c010ff5-0f31-466b-8ab4-28a535cae2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._jvm.Thread.currentThread().getContextClassLoader().getResources(\"com/datastax/spark/connector/util/Logging.class\").hasMoreElements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151db11c-4ebf-48b0-b2cd-3aa70e9e0f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по продуктам успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, avg, desc\n",
    "\n",
    "jar_path = \"/opt/shared-jars/postgresql-42.7.5.jar,/opt/shared-jars/spark-cassandra-connector-assembly_2.12-3.2.0.jar\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Cassandra Final Setup\") \\\n",
    "    .config(\"spark.jars\", jar_path) \\\n",
    "    .config(\"spark.driver.extraClassPath\", jar_path) \\\n",
    "    .config(\"spark.executor.extraClassPath\", jar_path) \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"my-cassandra\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = \"jdbc:postgresql://host.docker.internal:65432/mydatabase\"\n",
    "properties = {\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mysecretpassword\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "products_df = spark.read.jdbc(url=url, table=\"products\", properties=properties)\n",
    "sales_df = spark.read.jdbc(url=url, table=\"sales\", properties=properties)\n",
    "\n",
    "# === Топ-10 самых продаваемых продуктов ===\n",
    "top_products_df = sales_df.groupBy(\"sale_product_id\") \\\n",
    "    .agg(\n",
    "        sum(\"sale_quantity\").alias(\"total_quantity_sold\"),\n",
    "        sum(\"sale_total_price\").alias(\"total_revenue\"),\n",
    "        count(\"*\").alias(\"sales_count\")\n",
    "    ) \\\n",
    "    .alias(\"sales\") \\\n",
    "    .join(\n",
    "        products_df.alias(\"products\"),\n",
    "        col(\"sales.sale_product_id\") == col(\"products.sale_product_id\"),\n",
    "        \"left\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"sales.sale_product_id\").alias(\"product_id\"),\n",
    "        col(\"products.product_name\"),\n",
    "        col(\"products.product_category\"),\n",
    "        col(\"total_quantity_sold\"),\n",
    "        col(\"total_revenue\"),\n",
    "        col(\"sales_count\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"total_quantity_sold\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "# === Выручка по категориям продуктов ===\n",
    "revenue_by_category_df = sales_df.alias(\"sales\") \\\n",
    "    .join(products_df.alias(\"products\"), col(\"sales.sale_product_id\") == col(\"products.sale_product_id\"), \"left\") \\\n",
    "    .groupBy(\"products.product_category\") \\\n",
    "    .agg(sum(\"sales.sale_total_price\").alias(\"total_revenue\")) \\\n",
    "    .withColumnRenamed(\"product_category\", \"category\") \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "# === Средний рейтинг и количество отзывов по каждому продукту ===\n",
    "ratings_df = products_df.select(\n",
    "    col(\"sale_product_id\").alias(\"product_id\"),\n",
    "    \"product_name\",\n",
    "    \"product_category\",\n",
    "    \"product_rating\",\n",
    "    \"product_reviews\"\n",
    ").filter(col(\"product_rating\").isNotNull())\n",
    "\n",
    "# === Запись витрин в Cassandra ===\n",
    "top_products_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"top_selling_products\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "revenue_by_category_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"revenue_by_category\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "ratings_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"product_ratings\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"✅ Витрина по продуктам успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5bb18b-8fb6-49b1-8616-9415d1115f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по клиентам успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "customers_df = spark.read.jdbc(url=url, table=\"customers\", properties=properties)\n",
    "sales_df = spark.read.jdbc(url=url, table=\"sales\", properties=properties)\n",
    "\n",
    "# === Топ-10 клиентов с наибольшей общей суммой покупок ===\n",
    "top_customers_df = sales_df.groupBy(\"sale_customer_id\") \\\n",
    "    .agg(\n",
    "        sum(\"sale_total_price\").alias(\"total_spent\")\n",
    "    ) \\\n",
    "    .alias(\"sales\") \\\n",
    "    .join(\n",
    "        customers_df.alias(\"customers\"),\n",
    "        col(\"sales.sale_customer_id\") == col(\"customers.sale_customer_id\"),\n",
    "        \"left\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"sales.sale_customer_id\").alias(\"customer_id\"),\n",
    "        col(\"customers.customer_first_name\"),\n",
    "        col(\"customers.customer_last_name\"),\n",
    "        col(\"customers.customer_email\"),\n",
    "        col(\"customers.customer_country\"),\n",
    "        col(\"total_spent\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"total_spent\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "# === Распределение клиентов по странам ===\n",
    "customers_by_country_df = customers_df.groupBy(\"customer_country\") \\\n",
    "    .agg(count(\"*\").alias(\"customer_count\")) \\\n",
    "    .orderBy(desc(\"customer_count\"))\n",
    "\n",
    "# === Средний чек для каждого клиента ===\n",
    "avg_check_df = sales_df.groupBy(\"sale_customer_id\") \\\n",
    "    .agg(\n",
    "        (sum(\"sale_total_price\") / sum(\"sale_quantity\")).alias(\"avg_check\")\n",
    "    ) \\\n",
    "    .alias(\"sales\") \\\n",
    "    .join(\n",
    "        customers_df.alias(\"customers\"),\n",
    "        col(\"sales.sale_customer_id\") == col(\"customers.sale_customer_id\"),\n",
    "        \"left\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"sales.sale_customer_id\").alias(\"customer_id\"),\n",
    "        col(\"customers.customer_first_name\"),\n",
    "        col(\"customers.customer_last_name\"),\n",
    "        col(\"customers.customer_email\"),\n",
    "        col(\"customers.customer_country\"),\n",
    "        col(\"avg_check\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"avg_check\"))\n",
    "\n",
    "# === Запись витрин в Cassandra ===\n",
    "top_customers_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"top_customers\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "customers_by_country_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"customers_by_country\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "avg_check_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"average_check_per_customer\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"✅ Витрина по клиентам успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d945fede-6583-4414-bed1-3fc161cef6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по времени успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "sales_df = spark.read.jdbc(url=url, table=\"sales\", properties=properties)\n",
    "\n",
    "# === Месячные и годовые тренды продаж ===\n",
    "monthly_trends_df = sales_df \\\n",
    "    .withColumn(\"year\", year(\"sale_date\")) \\\n",
    "    .withColumn(\"month\", month(\"sale_date\")) \\\n",
    "    .groupBy(\"year\", \"month\") \\\n",
    "    .agg(\n",
    "        sum(\"sale_total_price\").alias(\"monthly_revenue\"),\n",
    "        sum(\"sale_quantity\").alias(\"monthly_quantity\")\n",
    "    ) \\\n",
    "    .orderBy(\"year\", \"month\")\n",
    "\n",
    "# === Сравнение выручки за разные года ===\n",
    "yearly_comparison_df = sales_df \\\n",
    "    .withColumn(\"year\", year(\"sale_date\")) \\\n",
    "    .groupBy(\"year\") \\\n",
    "    .agg(\n",
    "        sum(\"sale_total_price\").alias(\"total_revenue\"),\n",
    "        count(\"*\").alias(\"sales_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"year\")\n",
    "\n",
    "# === Средний размер заказа по месяцам ===\n",
    "avg_order_monthly_df = sales_df \\\n",
    "    .withColumn(\"year\", year(\"sale_date\")) \\\n",
    "    .withColumn(\"month\", month(\"sale_date\")) \\\n",
    "    .groupBy(\"year\", \"month\") \\\n",
    "    .agg(\n",
    "        (sum(\"sale_total_price\") / count(\"*\")).alias(\"avg_order_value\")\n",
    "    ) \\\n",
    "    .orderBy(\"year\", \"month\")\n",
    "\n",
    "# === Запись витрин в Cassandra ===\n",
    "monthly_trends_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"monthly_sales_trends\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "yearly_comparison_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"yearly_sales_summary\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "avg_order_monthly_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"monthly_avg_order_value\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"✅ Витрина по времени успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892410c1-72bf-4123-9a1e-1d84fbfc3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по магазинам успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "stores_df = spark.read.jdbc(url=url, table=\"stores\", properties=properties)\n",
    "sales_df = spark.read.jdbc(url=url, table=\"sales\", properties=properties)\n",
    "\n",
    "# === Топ-5 магазинов с наибольшей выручкой ===\n",
    "top_stores_df = sales_df.groupBy(\"store_name\") \\\n",
    "    .agg(\n",
    "        sum(\"sale_total_price\").alias(\"total_revenue\"),\n",
    "        count(\"*\").alias(\"sales_count\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"total_revenue\")) \\\n",
    "    .limit(5)\n",
    "\n",
    "# === Распределение продаж по городам и странам ===\n",
    "geo_sales_df = sales_df.alias(\"sales\") \\\n",
    "    .join(stores_df.alias(\"stores\"), col(\"sales.store_name\") == col(\"stores.store_name\"), \"left\") \\\n",
    "    .groupBy(\"stores.store_city\", \"stores.store_country\") \\\n",
    "    .agg(sum(\"sales.sale_total_price\").alias(\"total_revenue\")) \\\n",
    "    .withColumnRenamed(\"store_city\", \"city\") \\\n",
    "    .withColumnRenamed(\"store_country\", \"country\") \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "# === Средний чек по каждому магазину ===\n",
    "avg_check_per_store_df = sales_df.groupBy(\"store_name\") \\\n",
    "    .agg(\n",
    "        (sum(\"sale_total_price\") / count(\"*\")).alias(\"avg_receipt\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"avg_receipt\"))\n",
    "\n",
    "# === Запись витрин в Cassandra ===\n",
    "top_stores_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"top_stores_by_revenue\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "geo_sales_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"store_sales_by_location\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "avg_check_per_store_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"store_avg_check\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"✅ Витрина по магазинам успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45a8212-7932-4f78-a05a-7873e7087345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по поставщикам успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "suppliers_df = spark.read.jdbc(url=url, table=\"suppliers\", properties=properties)\n",
    "products_df = spark.read.jdbc(url=url, table=\"products\", properties=properties)\n",
    "sales_df = spark.read.jdbc(url=url, table=\"sales\", properties=properties)\n",
    "\n",
    "# === Топ-5 поставщиков с наибольшей выручкой ===\n",
    "supplier_revenue_df = sales_df.alias(\"sales\") \\\n",
    "    .join(products_df.alias(\"products\"), col(\"sales.sale_product_id\") == col(\"products.sale_product_id\"), \"left\") \\\n",
    "    .join(suppliers_df.alias(\"suppliers\"), col(\"products.product_brand\") == col(\"suppliers.supplier_name\"), \"left\") \\\n",
    "    .groupBy(\"suppliers.supplier_name\") \\\n",
    "    .agg(sum(\"sales.sale_total_price\").alias(\"total_revenue\")) \\\n",
    "    .orderBy(desc(\"total_revenue\")) \\\n",
    "    .limit(5)\n",
    "\n",
    "# === Средняя цена товаров от каждого поставщика ===\n",
    "avg_price_by_supplier_df = products_df.alias(\"products\") \\\n",
    "    .join(suppliers_df.alias(\"suppliers\"), col(\"products.product_brand\") == col(\"suppliers.supplier_name\"), \"left\") \\\n",
    "    .groupBy(\"suppliers.supplier_name\") \\\n",
    "    .agg(avg(\"products.product_price\").alias(\"avg_product_price\")) \\\n",
    "    .orderBy(desc(\"avg_product_price\"))\n",
    "\n",
    "# === Распределение продаж по странам поставщиков ===\n",
    "sales_by_supplier_country_df = sales_df.alias(\"sales\") \\\n",
    "    .join(products_df.alias(\"products\"), col(\"sales.sale_product_id\") == col(\"products.sale_product_id\"), \"left\") \\\n",
    "    .join(suppliers_df.alias(\"suppliers\"), col(\"products.product_brand\") == col(\"suppliers.supplier_name\"), \"left\") \\\n",
    "    .groupBy(\"suppliers.supplier_country\") \\\n",
    "    .agg(sum(\"sales.sale_total_price\").alias(\"total_revenue\")) \\\n",
    "    .withColumnRenamed(\"supplier_country\", \"country\") \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "# === Фильтрация null'ов по ключевому полю ===\n",
    "supplier_revenue_df_clean = supplier_revenue_df.filter(col(\"supplier_name\").isNotNull())\n",
    "avg_price_by_supplier_df_clean = avg_price_by_supplier_df.filter(col(\"supplier_name\").isNotNull())\n",
    "sales_by_supplier_country_df_clean = sales_by_supplier_country_df.filter(col(\"country\").isNotNull())\n",
    "\n",
    "# === Запись в Cassandra ===\n",
    "supplier_revenue_df_clean.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"top_suppliers_by_revenue\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "avg_price_by_supplier_df_clean.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"avg_price_by_supplier\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "sales_by_supplier_country_df_clean.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"sales_by_supplier_country\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "print(\"✅ Витрина по поставщикам успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156aa284-74ad-41e0-a250-e20f2fb1b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Витрина по качеству продукции успешно создана и загружена в Cassandra.\n"
     ]
    }
   ],
   "source": [
    "# === Продукты с наивысшим и наименьшим рейтингом ===\n",
    "extreme_ratings_df = products_df.select(\n",
    "    \"sale_product_id\", \"product_name\", \"product_category\", \"product_rating\"\n",
    ").filter(col(\"product_rating\").isNotNull()) \\\n",
    "    .orderBy(col(\"product_rating\").desc()) \\\n",
    "    .limit(5) \\\n",
    "    .union(\n",
    "        products_df.select(\n",
    "            \"sale_product_id\", \"product_name\", \"product_category\", \"product_rating\"\n",
    "        ).filter(col(\"product_rating\").isNotNull()) \\\n",
    "        .orderBy(col(\"product_rating\").asc()) \\\n",
    "        .limit(5)\n",
    "    )\n",
    "\n",
    "# === Корреляция между рейтингом и объёмом продаж ===\n",
    "rating_sales_corr_df = sales_df.alias(\"sales\") \\\n",
    "    .join(products_df.alias(\"products\"), col(\"sales.sale_product_id\") == col(\"products.sale_product_id\"), \"left\") \\\n",
    "    .groupBy(\"products.product_rating\") \\\n",
    "    .agg(sum(\"sales.sale_quantity\").alias(\"total_quantity_sold\")) \\\n",
    "    .orderBy(\"product_rating\")\n",
    "\n",
    "# === Продукты с наибольшим количеством отзывов ===\n",
    "most_reviewed_df = products_df.select(\n",
    "    \"sale_product_id\", \"product_name\", \"product_category\", \"product_reviews\"\n",
    ").filter(col(\"product_reviews\").isNotNull()) \\\n",
    "    .orderBy(desc(\"product_reviews\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "# === Запись в Cassandra ===\n",
    "extreme_ratings_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"extreme_rated_products\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "rating_sales_corr_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"rating_vs_sales_volume\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "most_reviewed_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"confirm.truncate\", \"true\") \\\n",
    "    .options(table=\"most_reviewed_products\", keyspace=\"analytics\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"✅ Витрина по качеству продукции успешно создана и загружена в Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c625b38-165d-4c0b-91cc-9ed38af6188d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
